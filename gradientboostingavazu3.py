# -*- coding: utf-8 -*-
"""gradientBoostingAvazu3.ipynb

Automatically generated by Colaboratory.


"""

from google.colab import drive
drive.mount('/content/gdrive')

from pandas import read_csv
import numpy as np
from dateutil import parser #parsa la data per una pi√π facile resa del codice
from matplotlib import pyplot

inputFile = "./gdrive/My Drive/Avazu/syte" 
        
datamini = read_csv(inputFile, header=0) #legge il csv

"""
seleziona le feature dichiarate
"""
def selectFeature(data, feature_names=''):

    for c in data.columns.values:
        if c not in feature_names:
            data = data.drop(c, axis=1)
    return data

df = datamini['device_id'].value_counts().reset_index()
df.columns = ['device_id', 'count']
#print(df)

df = np.array(df)

for i in range(len(df)):
    if (df[i,1] == 9):
        limite = i
        print(i)
        break

df = df[limite:, 0]
df = df.tolist()

datamini = datamini[~datamini['device_id'].isin(df)]
print(datamini.shape)

df = datamini['device_ip'].value_counts().reset_index()
df.columns = ['device_ip', 'count']
#print(df)

df = np.array(df)

for i in range(len(df)):
    if (df[i,1] == 9):
        limite = i
        print(i)
        break

df = df[limite:, 0]
df = df.tolist()


datamini = datamini[~datamini['device_ip'].isin(df)]
print(datamini.shape)


print(datamini.iloc[1])

features = ['click', 'banner_pos', 'app_id', 'app_domain', 'app_category', 'device_id',
       'device_ip', 'device_model', 'device_type', 'device_conn_type', 'ad_id',
       'lunghezza_banner', 'altezza_banner', 'ad_group_id', 'ad_sponsor_id']

datamini = datamini.rename(index=str, columns={"C14": "ad_id", "C15": "lunghezza_banner",
                                                "C16": "altezza_banner", "C17": "ad_group_id", "C21": "ad_sponsor_id"})

datamini = selectFeature(datamini, features)


datamini.shape

datamini = np.array(datamini)

for i in range(len(datamini)):
  datamini[i, 2] = hash(datamini[i, 2]) % (10**6)
  datamini[i, 3] = hash(datamini[i, 3]) % (10**6)
  datamini[i, 4] = hash(datamini[i, 4]) % (10**6)
  datamini[i, 5] = hash(datamini[i, 5]) % (10**6)
  datamini[i, 6] = hash(datamini[i, 6]) % (10**6)
  datamini[i, 7] = hash(datamini[i, 7]) % (10**6)

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

label = datamini[:,0]
data = datamini[:,1:]

print(data)
print(label)

train, validation, trainLabel, validationLabel = train_test_split(datamini, label, test_size=0.2)

train = np.float32(train)

trainLabel = np.array(trainLabel)

trainLabel = np.float32(trainLabel)

trainLabel.shape

import pandas as pd
import numpy as np

from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier

from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, precision_score, make_scorer, recall_score
from sklearn.model_selection import GridSearchCV, train_test_split

import io
from google.colab import files


gdb = GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='exponential', max_depth=4,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=200,
              n_iter_no_change=None, presort='auto', random_state=None,
              subsample=1.0, tol=0.0001, validation_fraction=0.2,
              verbose=1, warm_start=False)

from xgboost import XGBClassifier

gdb = XGBClassifier()


eval_set = [(validation, validationLabel)]

gdb.fit(train, trainLabel, eval_metric="error", eval_set=eval_set, verbose=True)

pred = gdb.predict(validation)



validationLabel  = np.float32(validationLabel)

pred

print(classification_report(pred, validationLabel))

gdb = GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='exponential', max_depth=5,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=200,
              n_iter_no_change=None, presort='auto', random_state=None,
              subsample=1.0, tol=0.0001, validation_fraction=0.2,
              verbose=1, warm_start=False)

gdb.fit(train, trainLabel)

pred = gdb.predict(validation)

validationLabel  = np.float32(validationLabel)

print(classification_report(pred, validationLabel))

accuracy = accuracy_score(validationLabel, pred)
print("Accuracy: %.2f%%" % (accuracy * 100.0))

gdb = GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='exponential', max_depth=5,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=200,
              n_iter_no_change=None, presort='auto', random_state=None,
              subsample=0.6, tol=0.0001, validation_fraction=0.2,
              verbose=1, warm_start=False)

gdb.fit(train, trainLabel)

pred = gdb.predict(validation)

validationLabel  = np.float32(validationLabel)

print(classification_report(pred, validationLabel))

gdb = GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='exponential', max_depth=5,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=10,
              n_iter_no_change=None, presort='auto', random_state=None,
              subsample=0.6, tol=0.0001, validation_fraction=0.2,
              verbose=1, warm_start=False)

gdb.fit(train, trainLabel)

pred = gdb.predict(validation)

validationLabel  = np.float32(validationLabel)

print(classification_report(pred, validationLabel))

from xgboost import XGBClassifier

model = XGBClassifier()
model.fit(train, trainLabel)

# make predictions for test data
y_pred = model.predict(validation)
predictions = [round(value) for value in y_pred]
# evaluate predictions
accuracy = accuracy_score(validationLabel, predictions)
print("Accuracy: %.2f%%" % (accuracy * 100.0))

from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score

precisione0 = precision_score(validationLabel, predictions)
recupero0 = recall_score(validationLabel, predictions)
f1_0 = f1_score(validationLabel, predictions)
accuracy = accuracy_score(validationLabel, predictions)

print(accuracy)
print(precisione0)
print(recupero0)
print(f1_0)